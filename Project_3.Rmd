---
title: 'ST 558 Project 3: `r params$rep_title` Analysis Report'
author: "Suyog Dharmadhikari; Bennett McAuley"
date: "2022-11-02"
output: 
  html_document:
    toc: true
params:
  channel: NULL
  rep_title: ''
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
set.seed(152)

library(tidyverse)
library(caret)
library(leaps)
library(gbm)
library(ggcorrplot)
```

## Introduction

The goal of this report is to create and compare predictive models using [Online News Popularity](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity) data from the UCI Machine Learning Repository.

This data contains information about articles published by Mashable over a period of two years--specifically the statistics associated with them.

The purpose of this analysis is to use linear regression and ensemble tree-based methods to predict the number of `shares`--our target variable--subset by data channel. For more details about these methods, see the _Modeling_ section.

According to the data description, there are 39,797 observations and 61 variables present. 58 of them are predictors, but using all of them would be inefficient and show glaring redundancies. Instead, the ones that will be used were chosen intuitively--what might encourage a user to share an article, what underlying forces may influence them, and what would make for good exploratory analysis:

1. `average_token_length` - Average length of the words in the content
2. `avg_negative_polarity` - Avg. polarity of negative words
3. `global_rate_positive_words` - Rate of positive words in the content
4. `global_sentiment_polarity` - Text sentiment polarity
5. `global_subjectivity` - Text subjectivity
6. `is_weekend` - Was the article published on the weekend?
7. `kw_avg_max` - Best keyword (avg. shares)
8. `kw_avg_min` - Worst Keyword (avg. shares)
9. `kw_max_max` - Best keyword (max shares)
10. `kw_min_min` - Worst keyword (min shares)
11. `n_non_stop_words` - Rate of non-stop words in the content
12. `n_tokens_content` - Number of words in the content
13. `n_tokens_title` - Number of words in the title
14. `n_unique_tokens` - Rate of unique words in the content
15. `num_hrefs` - Number of links
16. `num_imgs` - Number of images
17. `num_self_hrefs` - Number of links to other articles published by Mashable
18. `num_videos` - Number of videos
19. `self_reference_avg_shares` - Avg. shares of referenced articles in Mashable
20. `title_sentiment_polarity` - Title polarity
21. `weekday_is_monday` - Was the article published on a Monday?
22. `weekday_is_tuesday` - Was the article published on a Tuesday?
23. `weekday_is_wednesday` - Was the article published on a Wednesday?
24. `weekday_is_thursday` - Was the article published on a Thursday?
25. `weekday_is_friday` - Was the article published on a Friday?
26. `weekday_is_saturday` - Was the article published on a Saturday?
27. `weekday_is_sunday` - Was the article published on a Sunday?

Which we store in a vector for fast retrieval:

```{r vars}
news.vars <- c('n_tokens_title', 'n_tokens_content', 'n_non_stop_words', 'num_hrefs',
               'num_self_hrefs', 'num_imgs', 'num_videos', 'average_token_length',
               'kw_max_max', 'kw_min_min', 'kw_avg_max', 'kw_avg_min',
               'self_reference_avg_sharess','is_weekend', 'global_subjectivity', 'global_sentiment_polarity',
               'global_rate_positive_words', 'avg_negative_polarity', 'n_unique_tokens', 'title_sentiment_polarity',
               'weekday_is_sunday', 'weekday_is_monday', 'weekday_is_tuesday', 'weekday_is_wednesday',
               'weekday_is_thursday', 'weekday_is_friday', 'weekday_is_saturday'
               )
```

## The Data

For this analysis, we will consider a single source for the data channel. In other words, we subset the data to the _`r params$rep_title`_ channel.

So, we read in the data, perform the filter, and convert `is_weekend` into a binary factor:

```{r read data}
news <- read_csv("OnlineNewsPopularity.csv")
fltr <- paste0("data_channel_is_", params$channel)
# fltr <- "data_channel_is_tech"
news.tbl <- news %>% filter(get(fltr) == 1) %>% 
  select(all_of(news.vars), shares) %>%
  mutate(is_weekend = as.factor(is_weekend))

head(news.tbl)
```

## Summarizations

Now that our data has been manipulated and filtered, we can perform a simple EDA.

### Summary Statistics

First and foremost, we want to know what range of values we might expect when predicting for `shares`. The following table shows basic summary statistics about the variable:

```{r five_sum}
s <- summary(news.tbl$shares)

tibble(var = 'shares', min = s[1], max = s[6], mean = s[3], stddev = sd(news.tbl$shares))
```

If the maximum is tremendously larger in scale than the mean, then it is very likely an outlier. If the standard deviation is larger than the mean, then the number of shares varies greatly. Furthermore, the higher it is, the more disperse they are from the mean. The inverse also applies for a smaller standard deviation (i.e. the smaller, the less disperse).

It would also be good to know relationships between some of the variables present--and not just to `shares`. Observe the following correlation matrix of variables related to content sentiment. A value of 0 indicates no correlation and 1 indicates perfect correlation. The closer a value is to 1(+/-), the stronger the relationship is. The closer to 0, the weaker.

```{r corr}
c <- news.tbl %>%
  select(avg_negative_polarity,
         global_rate_positive_words,
         global_sentiment_polarity,
         global_subjectivity,
         shares)

round(cor(c),2)
```
The new variable **popularity** is set up so that news is considered `popular` if it receives more shares than the median shares, else it is considered `unpopular`.`table()` gives details about **count** of popular and unpopular news.
```{r tablePopCount, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}

  news.tbl$popularity <- ifelse(news.tbl$shares < mean(news.tbl$shares),
  "Unpopular", "Popular"
)

table(news.tbl$popularity)
  
```
The contingency table below depicts the relationship between the **popularity** of a news channel and whether or not it was **published on the weekend**. It informs us whether or not popular news was published over the weekend. Whether or not unpopular news was published over the weekend.
```{r conTable, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}

   table(news.tbl$popularity,news.tbl$is_weekend)

```

### Plots

For visual analysis, we first construct a density plot to compare the densities of `shares` between the weekend (`is_weekend = 1`) and weekdays (`is_weekend = 0`). Observe the patterns generated for similarities and/or differences.

```{r density}
g <- ggplot(data = news.tbl, aes(x = shares))

g + geom_density(adjust = 0.5, alpha = 0.5, aes(fill = is_weekend)) +
  xlim(0, 10000) +
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Density Plot for Shares",
       subtitle = paste("channel = ", params$channel),
       x = "# of Shares",
       y = "Density")
```

The second visual is a scatterplot with a trend line. The number of words in the content is on the x-axis and the rate of unique words on the y-axis. If the data points and trend line show an upward trend, then articles with more words tend to have a larger rate of unique ones. If there is a downward trend, then articles with more words tend to have a smaller rate of unique ones.

```{r scatter}
p <- ggplot(news.tbl, aes(x = n_tokens_content, y = n_unique_tokens))

p + geom_point() +
  geom_smooth(method = glm, col = "Blue") +
  labs(title = "Scatterplot for n_tokens_content vs n_unique_tokens",
       subtitle = paste("channel = ", params$channel),
       x = "# of Words in Article",
       y = "Rate of Unique Words in Article")
```

This subsequent bar plot shows a comparison between the total number of articles published on each day of the week and the total shares of those articles. Observe any interestingly sized columns that one might think would be higher or lower than others. Articles published on which day tend to get shared the most? Which one gets the least?

```{r box}

plt <- news.tbl %>% pivot_longer(cols = starts_with("weekday_is_"),
               names_to = "day",
               names_prefix = "weekday_is_",
               names_transform = as.factor,
               values_to = "count") %>%
  filter(count == 1) %>%
  select(-count, -starts_with("weekday_is_"))

#Reordering days
plt$day <- factor(plt$day,
    levels = c("monday", "tuesday", "wednesday", "thursday", "friday", "saturday", "sunday"))


plt <- plt %>%
  select(day, shares) %>%
  group_by(day) %>%
  summarise(articles = n(), shares = sum(shares))

plt <- reshape2::melt(plt, id.vars = c("day"))

p <- ggplot(plt, aes(x = day, y = value, fill = day))

p + geom_col() +
  facet_wrap(vars(variable), scales = "free") +
  scale_y_continuous(labels = scales::comma) +
  guides(x = guide_axis(angle = 45), fill = "none") +
  labs(title = "Total # of Articles vs Total # of Shares per Publishing Day",
       subtitle = paste("channel = ", params$channel),
       x = "Day",
       y = '')

```

The code chunk below, tells us about the number of shares of a particular published news with number of images in the published news.It also tells us about the popularity of the news published with images. 

```{r barPlot, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}

  ggplot(news.tbl, aes(fill= popularity, y=shares, x=num_imgs)) +
  geom_bar(position='dodge', stat='identity',  width = 0.98) +
  ggtitle('Relation between number of images and shares') +
  xlab('Number of images in the news published') +
  ylab('Shares') +
  ylim(0, 100000)
```

Correlation plots are used to find out the **correlation** between two variables in the given data set. In the code chunk below, we have used `ggcorrplt()` to plot the correlation between all the variables in the data set and identify the most **correlated variables**. A **violet** color circle shows there is **negative** correlation between the two respective variables and a **dark orange** color is **positive** correlation between two variables. 

```{r corrPlot, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
   
    corr <- cor(select_if(news.tbl, is.numeric))
    ggcorrplot(corr, 
                method = "circle",
                type = "lower",
                outline.color = "black",
                 lab_size = 6)

```

In the code chunk a scatter plot with a trend line. The number of words in the content is on the x-axis and the number of shares on the y-axis. If the data points and trend line show an upward trend, then articles with more words tend to have more number of shares. If there is a downward trend, then articles with more words tend to have a smaller number of shares.

```{r scattPlot, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
   
  ggplot(news.tbl, aes(y=shares, x=n_tokens_content)) + 
    geom_point(aes(color=popularity)) +
    geom_smooth() + 
    ylim(0, 100000)
```

## Modeling

The goal now is to create models for predicting the number of `shares` using linear regression and ensemble trees. Before that, the data is split into a training (70%) and test (30%) set.

```{r split}
i <- createDataPartition(news.tbl[[1]], p = 0.7, list = FALSE)

train <- news.tbl[i,]
test <- news.tbl[-i,]
```

### Linear Regression

The linear regression model is fit using variables chosen from forward stepwise selection.The leaps library's `regsubsets()` function performs best subset selection by identifying the best model with a given number of predictors, where best is quantified using **RSS**. The syntax is **identical** to that of `lm()`. The summary() command returns the best set of variables for each model size. In the code chunk below, we find the best predictors subset, then **r^2** value is used to determine the number of predictors that can give **best** model results. Then we create a formula that can be used to train the model by using `as.formula()` and `paste0()` in R.

```{r regressionFormula1, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
fwdVars <- regsubsets(shares ~ ., train, method = "forward")

fwdSumm <- summary(fwdVars)

adjRNum <- which.max(fwdSumm$adjr2)

bestModels <- fwdSumm$which[adjRNum,-1]

varNames <- names(which(bestModels == TRUE))

predictorFormulaPt2 <- paste(varNames, collapse = "+")

modelFormula <- as.formula(paste0("shares", "~", predictorFormulaPt2))

modelFormula

```

A statistical technique that aims to demonstrate a link between variables is **linear regression**. A dependent variable's nature and degree of connection with a group of independent variables are assessed using linear regression. We can make predictions of shares using linear regression models.

In the code chunk below, firstly we have converted categorical variables into numerical variables using `dummyVars()`. `gsub()` is used to **rename** the column names in order to match with the column names generated by `regsubsets()` in the function above. **Caret** package was used to train a linear regression model by using the best predictors obtained from **`regsubsets()`**. We have **standardized** the model using `center and scale`. **Cross validation** is used to avoid over fitting and add generalization in our model. 

```{r regressModel, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}

set.seed(400)
# convert categorical variables into numeric variables i.e one hot encoding
dummies <- dummyVars(shares ~ is_weekend+popularity, data = train)
trainDF <- as_tibble(predict(dummies, newdata = train)) %>%
    bind_cols(select(train,-is_weekend,-popularity))

# Replace . with spaces in column names to match the output names from regsubsets
names(trainDF) <- gsub(x = names(trainDF), pattern = "\\.", replacement = "") 

forwardFit <- train(modelFormula,
                    data = trainDF,
                    method = "lm",
                    metric = "Rsquared",
                    preProcess = c("center","scale"),
                    trControl = trainControl(method = "cv", number = 10))

summary(forwardFit)

```

```{r regressModelPredictFwd, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
# convert categorical variables into numeric variables i.e one hot encoding
dummies <- dummyVars(shares ~ is_weekend+popularity, data = test)
testDF <- as_tibble(predict(dummies, newdata = test)) %>%
    bind_cols(select(test,-is_weekend,-popularity))

  predLR <- predict(forwardFit,newdata = testDF)
  
  predResultsFwd <- postResample(predLR,obs = testDF$shares)
  
  predResultsFwd
  
```

This second linear regression model is fit using variables chosen from backwards stepwise selection.

The `regsubsets` function is called, and the summary is returned to grab the models of $n$ terms that have the optimal values for $R^2$, Mallows' Cp, and BIC. As performance will vary, the mode value between the three is chosen as the 'best'.

```{r regression 2}
backVars <- regsubsets(shares ~ ., train, method = "backward")

backSumm <- summary(backVars, all.best = FALSE)

met <- c(R2 = which.max(backSumm$rsq), 
     Cp = which.min(backSumm$cp),
     BIC = which.min(backSumm$bic)
)

M <- which.max(tabulate(met))
```

The most frequent number is `r M`. The variables present in this size model are:

```{r coef return}
terms <- coef(backVars, M)
terms
```

Now, the model can be trained. The coefficient names are grabbed from the backwards selection, and input as a subset of the training data. The variables are scaled to account for the vastly different magnitudes between them, and to prevent any extreme coefficient values because of this.

```{r reg train}
prd <- names(terms)
prd <- replace(prd, prd %in% c('(Intercept)', 'is_weekend1'), c('shares', 'is_weekend'))

BackwardFit <- train(shares ~ .,
                    data = train[,prd],
                    method = "lm",
                    metric = "Rsquared",
                    preProcess = c("scale"),
                    trControl = trainControl(method = "cv", number = 10))

summary(BackwardFit)

```

```{r regressModelPredictBck, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
# convert categorical variables into numeric variables i.e one hot encoding

  predLRBck <- predict(BackwardFit,newdata = test)
  
  predResultsBck <- postResample(predLRBck,obs = test$shares)
  
  predResultsBck
  
```

### Random Forest

**Random forest** uses same idea as bagging tree models. That means it is a bootstrap aggregation method, but only difference is that in random forest we **randomly select subset of predictors** instead of using all the predictors. This is because, if a really strong predictor exists, **every** bootstrap tree will probably use it for the **first** split. This will result in making bagged trees predictions more **correlated** and **variance** will be **large** in aggregation. Hence, in random forest we avoid this limitation by using a random subset of predictors for each bootstrap sample/tree fit. 
In the code chunk below, `Caret` package was used to train the rf forest model and the evaluation metric used for the fit is `Rsquared`. We have tuned the model by using tuning parameter `mtry` ad used **5 folds cross validation** for finding best fit.

```{r randomForestModel, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}

set.seed(123)

#5 folds cross validation
control <- trainControl(method='cv', 
                        number=5)

tunegrid <- data.frame(mtry = 1:9)
rfFit <- train(modelFormula, 
                      data=trainDF, 
                      method='rf', 
                      metric='Rsquared', 
                      tuneGrid=tunegrid, 
                      trControl=control)

rfFit$bestTune

varImp(rfFit$finalModel) %>% arrange(desc(Overall))

```

```{r rfModelPredict, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
# convert categorical variables into numeric variables i.e one hot encoding
dummies <- dummyVars(shares ~ is_weekend+popularity, data = test)
testDF <- as_tibble(predict(dummies, newdata = test)) %>%
    bind_cols(select(test,-is_weekend,-popularity))

  predRF <- predict(rfFit,newdata = testDF)
  
  predResultsRF <- postResample(predRF,obs = testDF$shares)
  
  predResultsRF
  
```
### Boosted Tree Model

Boosting centers around the idea of sequential learning--taking information from preceding iterations as a basis for calculating the current iteration. Boosted trees are ensemble tree models consisting of a group of trees that are built in sequence, including errors from previous trees for predictions.

Boosted trees also have a unique characteristic of _slow_ training. This is controlled by $\lambda$, a shrinkage parameter. The two other notable parameters for training a boosted tree are $B$ (the number of times the algorithm performs its procedure; `n.trees` in R) and $d$ (the number of splits; `interaction.depth` in R), both of which can be selected with cross-validation.

For regression, the boosting algorithm proceeds as follows:

1. The predictions are initialized to 0--$\hat{y}(x)=0$
2. The residuals between observed and predicted values are calculated
3. A tree with $d$ splits and $d+1$ terminal nodes is fit using the residuals as the response--denoted by $\hat{y}^b(x)$
4. The overall prediction is updated by recursively adding these pseudo-responses--$\hat{y}(x) +=\lambda\hat{y}^b(x)$ 
5. Residuals for new predictions are updated
6. Repeat $B$ times

This model is fit using `cv = 10`, and the `train` function will determine the optimal values of the parameters for us.

```{r boost train, results = 'hide', cache = TRUE}
#Output for this chunk is hidden as it is rather long and does not provide information needed for reporting
boostFit <- train(shares ~ .,
              method = "gbm",
              data = train,
              trControl = trainControl(method = "cv", number = 10))
```

During training, the optimal values for the tuning parameters were found to be:

```{r boost param}
boostFit$bestTune
```

Since coefficients aren't interpretable for boosted trees, the calculation of variable importance for the final model is shown instead, in descending order:

```{r boost vars}
varImp(boostFit$finalModel) %>% arrange(desc(Overall))
```

```{r boostModelPredict, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}
# convert categorical variables into numeric variables i.e one hot encoding
  predBoost <- predict(boostFit,newdata = test)
  
  predResultsBoost <- postResample(predBoost,obs = test$shares)
  
  predResultsBoost
  
```

```{r modelComparison, echo=TRUE, eval=TRUE,warning=FALSE,message=FALSE}

rmseModels <- c(predResultsFwd[[1]],predResultsBck[[1]],predResultsRF[[1]],predResultsBoost[[1]])

modelName <- c("Linear regression with forward selection","Linear regression with backward selection","Random forest","Boosted tree")

resultsDF <- data.frame(modelName,rmseModels)


bestModelName <- filter(resultsDF,rmseModels == min(rmseModels))[[1]]

paste0("The best model for the selected data channel is : ", bestModelName)

```
